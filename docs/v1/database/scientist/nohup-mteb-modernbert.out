2025-12-16 23:37:10,267 - INFO - ================================================================================
2025-12-16 23:37:10,267 - INFO - MTEB Benchmark for nomic-ai/modernbert-embed-base
2025-12-16 23:37:10,267 - INFO - ================================================================================
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,267 - INFO - Mode: FULL
2025-12-16 23:37:10,267 - INFO -   - Running all tasks
2025-12-16 23:37:10,267 - INFO -   - Task types: ['Retrieval']
2025-12-16 23:37:10,267 - INFO -   - Device: auto-detect
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,267 - INFO - This will run MTEB retrieval tasks to get benchmark scores.
2025-12-16 23:37:10,267 - INFO - Note: Full MTEB can take hours. Progress will be logged to:
2025-12-16 23:37:10,267 - INFO -   - Console (stdout)
2025-12-16 23:37:10,267 - INFO -   - Log file: /Users/hohyunjeon/Documents/projects/out_of_context/docs/v1/database/scientist/mteb-modernbert.log
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,267 - INFO - Model Requirements (from model card):
2025-12-16 23:37:10,267 - INFO -   - transformers>=4.48.0 (checking version...)
2025-12-16 23:37:10,267 - INFO -   - Prefixes required: 'search_query: ' for queries, 'search_document: ' for documents
2025-12-16 23:37:10,267 - INFO -   - MTEB should handle prefixes automatically via model metadata
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,267 - INFO - Hardware acceleration:
2025-12-16 23:37:10,267 - INFO -   - macOS: MPS (Metal Performance Shaders) will be used if available
2025-12-16 23:37:10,267 - INFO -   - CUDA: Will be used if available (Linux/Windows)
2025-12-16 23:37:10,267 - INFO -   - Flash Attention: Not available on macOS (CUDA-only)
2025-12-16 23:37:10,267 - INFO -   - Note: ModernBERT-base supports efficient inference with unpadding and Flash Attention
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,267 - INFO - ================================================================================
2025-12-16 23:37:10,267 - INFO - MTEB Benchmark: nomic-ai/modernbert-embed-base
2025-12-16 23:37:10,267 - INFO - ================================================================================
2025-12-16 23:37:10,267 - INFO - Start time: 2025-12-16T23:37:10.267829
2025-12-16 23:37:10,267 - INFO - 
2025-12-16 23:37:10,293 - INFO - ✅ MPS (Metal Performance Shaders) available - using GPU acceleration
2025-12-16 23:37:10,293 - INFO -    MPS config: HIGH_WATERMARK_RATIO=not set, FALLBACK=not set
2025-12-16 23:37:10,293 - INFO - ⚠️  Note: MPS may have issues with large tensors. Will fallback to CPU if needed.
2025-12-16 23:37:10,293 - INFO - Using device: mps
2025-12-16 23:37:10,293 - INFO - 
2025-12-16 23:37:10,293 - INFO - Loading model: nomic-ai/modernbert-embed-base
2025-12-16 23:37:10,293 - INFO - 
2025-12-16 23:37:10,293 - INFO - ⚠️  IMPORTANT: This model requires prefixes for optimal performance:
2025-12-16 23:37:10,293 - INFO -    - Queries: 'search_query: ' prefix
2025-12-16 23:37:10,293 - INFO -    - Documents: 'search_document: ' prefix
2025-12-16 23:37:10,293 - INFO -    MTEB should handle this automatically via model metadata.
2025-12-16 23:37:10,293 - INFO - 
2025-12-16 23:37:10,294 - INFO - Load pretrained SentenceTransformer: nomic-ai/modernbert-embed-base
2025-12-16 23:37:13,024 - INFO - ✅ Model loaded successfully
2025-12-16 23:37:13,024 - INFO -    Max sequence length: 8192
2025-12-16 23:37:13,024 - INFO -    Embedding dimension: 768
2025-12-16 23:37:13,024 - INFO -    Device: mps
2025-12-16 23:37:13,024 - INFO - 
2025-12-16 23:37:13,024 - INFO -    Model configuration verified:
2025-12-16 23:37:13,024 - INFO -    - Prefixes should be handled automatically by MTEB
2025-12-16 23:37:13,024 - INFO -    - If results seem low, verify prefixes are being applied
2025-12-16 23:37:13,024 - INFO -    - Using batch_size=4 for MPS compatibility
2025-12-16 23:37:13,024 - INFO - Using specified task types: ['Retrieval']
2025-12-16 23:37:13,024 - INFO - 
2025-12-16 23:37:13,024 - INFO - Fetching tasks...
2025-12-16 23:37:13,278 - INFO - Found 361 tasks
2025-12-16 23:37:13,278 - INFO - Running all 361 tasks
2025-12-16 23:37:13,278 - INFO - 
2025-12-16 23:37:13,278 - INFO - ================================================================================
2025-12-16 23:37:13,278 - INFO - Running MTEB evaluation on 361 tasks...
2025-12-16 23:37:13,278 - INFO - ================================================================================
2025-12-16 23:37:13,278 - INFO - 
2025-12-16 23:37:13,278 - INFO - 
2025-12-16 23:37:13,278 - INFO - [1/361] Starting: task_1
2025-12-16 23:37:13,278 - INFO -   Start time: 2025-12-16T23:37:13.278932
2025-12-16 23:37:15,087 - INFO - Loading qrels...
2025-12-16 23:37:16,234 - INFO - Loaded 699 TEST qrels.
2025-12-16 23:37:16,234 - INFO - Loading Corpus...
2025-12-16 23:37:16,912 - INFO - Loaded 22998 TEST Documents.
2025-12-16 23:37:16,912 - INFO - Doc Example: {'id': '51829', 'title': 'How can show android tablet as a external storage to PC?', 'text': "I want to send files to android tablet with a application from PC. - I can send files directly to tablet (2.3 android OS) PC see it as a external usb drive. - But i can't send files to tablet (4.2 android OS), because PC see it as a portable media player.(MTP) - How can i fix this problem ? - How can show my device as a external drive? my application that sent files written via Delphi."}
2025-12-16 23:37:16,912 - INFO - Loading Queries...
2025-12-16 23:37:17,884 - INFO - Loaded 699 TEST queries.
2025-12-16 23:37:17,884 - INFO - Query Example: {'id': '11546', 'text': 'Android chroot ubuntu - is it possible to get ubuntu to recognise usb devices'}
2025-12-16 23:37:17,901 - INFO - Running task CQADupstackAndroidRetrieval (split='test', hf_subset='default')...
2025-12-16 23:37:17,915 - INFO - Running retrieval task - Indexing corpus...
2025-12-16 23:37:17,919 - INFO - Running retrieval task - Searching queries...
2025-12-16 23:37:17,929 - INFO - Using prompt_name='query' for task=CQADupstackAndroidRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-16 23:37:22,973 - INFO - Performing full corpus search...
2025-12-16 23:37:22,973 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-16 23:37:22,973 - INFO - Encoding Batch 1/1...
2025-12-16 23:37:23,229 - INFO - Using prompt_name='document' for task=CQADupstackAndroidRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-16 23:59:03,630 - INFO - Computing Similarities...
2025-12-16 23:59:04,108 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-16 23:59:04,701 - INFO - Running retrieval task - Finished.
2025-12-16 23:59:04,746 - INFO - ✓ Finished evaluation for CQADupstackAndroidRetrieval
2025-12-16 23:59:06,118 - INFO - Loading qrels...
2025-12-16 23:59:07,048 - INFO - Loaded 1570 TEST qrels.
2025-12-16 23:59:07,048 - INFO - Loading Corpus...
2025-12-16 23:59:07,926 - INFO - Loaded 40221 TEST Documents.
2025-12-16 23:59:07,927 - INFO - Doc Example: {'id': '11547', 'title': 'Is there a word meaning "an unwanted eponym"?', 'text': 'An eponym is one way to eternal (if posthumous) fame. But is there a word meaning an eponym someone would sooner not have? (One would presume that Captain Charles _Boycott_ , Mr Justice _Lynch_ , and Patrick _Hooligan_ would not appreciate their undying notoriety.)'}
2025-12-16 23:59:07,927 - INFO - Loading Queries...
2025-12-16 23:59:08,746 - INFO - Loaded 1570 TEST queries.
2025-12-16 23:59:08,746 - INFO - Query Example: {'id': '19399', 'text': 'Is "a wide range of features" singular or plural?'}
2025-12-16 23:59:08,774 - INFO - Running task CQADupstackEnglishRetrieval (split='test', hf_subset='default')...
2025-12-16 23:59:08,813 - INFO - Running retrieval task - Indexing corpus...
2025-12-16 23:59:08,813 - INFO - Running retrieval task - Searching queries...
2025-12-16 23:59:08,847 - INFO - Using prompt_name='query' for task=CQADupstackEnglishRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-16 23:59:15,577 - INFO - Performing full corpus search...
2025-12-16 23:59:15,577 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-16 23:59:15,577 - INFO - Encoding Batch 1/1...
2025-12-16 23:59:16,017 - INFO - Using prompt_name='document' for task=CQADupstackEnglishRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 00:07:35,691 - INFO - Computing Similarities...
2025-12-17 00:07:36,683 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 00:07:37,807 - INFO - Running retrieval task - Finished.
2025-12-17 00:07:37,823 - INFO - ✓ Finished evaluation for CQADupstackEnglishRetrieval
2025-12-17 00:07:38,999 - INFO - Loading qrels...
2025-12-17 00:07:40,292 - INFO - Loaded 1595 TEST qrels.
2025-12-17 00:07:40,292 - INFO - Loading Corpus...
2025-12-17 00:07:44,486 - INFO - Loaded 45301 TEST Documents.
2025-12-17 00:07:44,486 - INFO - Doc Example: {'id': '11542', 'title': 'Supreme Commander 2 - Build Orders', 'text': 'What\'s your Supreme Commander 2 build order. I don\'t just want "6 mass extractors, 2 power and a factory". List of building and units out to the second or third factory, please.'}
2025-12-17 00:07:44,486 - INFO - Loading Queries...
2025-12-17 00:07:45,914 - INFO - Loaded 1595 TEST queries.
2025-12-17 00:07:45,914 - INFO - Query Example: {'id': '82449', 'text': 'Can the trophy system protect me against bullets?'}
2025-12-17 00:07:45,940 - INFO - Running task CQADupstackGamingRetrieval (split='test', hf_subset='default')...
2025-12-17 00:07:45,961 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 00:07:45,961 - INFO - Running retrieval task - Searching queries...
2025-12-17 00:07:46,010 - INFO - Using prompt_name='query' for task=CQADupstackGamingRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 00:07:51,946 - INFO - Performing full corpus search...
2025-12-17 00:07:51,946 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 00:07:51,946 - INFO - Encoding Batch 1/1...
2025-12-17 00:07:53,137 - INFO - Using prompt_name='document' for task=CQADupstackGamingRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 00:16:01,854 - WARNING - ⚠️  MPS error detected: MPS backend out of memory (MPS allocated: 14.01 GiB, other allocations: 24.04 GiB, max allowed: 42.43 GiB). Tried to allocate 12.00 GiB on private poo...
2025-12-17 00:16:01,861 - WARNING -    Falling back to CPU for this task...
2025-12-17 00:16:01,923 - INFO - Load pretrained SentenceTransformer: nomic-ai/modernbert-embed-base
2025-12-17 00:16:04,187 - INFO - No batch size defined in encode_kwargs. Setting `encode_kwargs['batch_size'] = 32`. Explicitly set the batch size to silence this message.
2025-12-17 00:16:04,202 - INFO - Results for CQADupstackAndroidRetrieval already exist in cache. Skipping evaluation and loading results.
2025-12-17 00:16:04,203 - INFO - Results for CQADupstackEnglishRetrieval already exist in cache. Skipping evaluation and loading results.
2025-12-17 00:16:04,203 - INFO - Running task CQADupstackGamingRetrieval (split='test', hf_subset='default')...
2025-12-17 00:16:04,306 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 00:16:04,306 - INFO - Running retrieval task - Searching queries...
2025-12-17 00:16:13,110 - INFO - Performing full corpus search...
2025-12-17 00:16:13,110 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 00:16:13,111 - INFO - Encoding Batch 1/1...
2025-12-17 00:40:52,517 - INFO - Computing Similarities...
2025-12-17 00:40:53,491 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 00:40:54,617 - INFO - Running retrieval task - Finished.
2025-12-17 00:40:54,636 - INFO - Unloaded dataset CQADupstackGamingRetrieval from memory.
2025-12-17 00:40:54,636 - INFO - ✓ Finished evaluation for CQADupstackGamingRetrieval
2025-12-17 00:40:56,606 - INFO - Loading qrels...
2025-12-17 00:40:57,755 - INFO - Loaded 885 TEST qrels.
2025-12-17 00:40:57,755 - INFO - Loading Corpus...
2025-12-17 00:41:02,093 - INFO - Loaded 37637 TEST Documents.
2025-12-17 00:41:02,093 - INFO - Doc Example: {'id': '73399', 'title': 'Satellite image display with the help of GeoServer and OpenLayers', 'text': "There is a satellite image it's size is 10 GB and I need to display this image using GeoServer and OpenLayers. When user select the Satellite image in the layer switcher need to display image within 10 seconds. I tried geopdf but the image quality loss isn't acceptable to customer. I want to achieve 10 seconds response time using 32 GB satellite image. Please advice me how to achieve this? Thanks in advance."}
2025-12-17 00:41:02,093 - INFO - Loading Queries...
2025-12-17 00:41:03,590 - INFO - Loaded 885 TEST queries.
2025-12-17 00:41:03,590 - INFO - Query Example: {'id': '52462', 'text': 'Calculating mean upslope aspect from each cell in DEM using Python?'}
2025-12-17 00:41:03,599 - INFO - Running task CQADupstackGisRetrieval (split='test', hf_subset='default')...
2025-12-17 00:41:03,610 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 00:41:03,610 - INFO - Running retrieval task - Searching queries...
2025-12-17 00:41:03,636 - INFO - Using prompt_name='query' for task=CQADupstackGisRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 00:41:07,373 - INFO - Performing full corpus search...
2025-12-17 00:41:07,373 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 00:41:07,374 - INFO - Encoding Batch 1/1...
2025-12-17 00:41:08,244 - INFO - Using prompt_name='document' for task=CQADupstackGisRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 02:40:24,635 - INFO - Computing Similarities...
2025-12-17 02:40:25,603 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 02:40:26,280 - INFO - Running retrieval task - Finished.
2025-12-17 02:40:26,292 - INFO - ✓ Finished evaluation for CQADupstackGisRetrieval
2025-12-17 02:40:30,267 - INFO - Loading qrels...
2025-12-17 02:40:32,352 - INFO - Loaded 804 TEST qrels.
2025-12-17 02:40:32,352 - INFO - Loading Corpus...
2025-12-17 02:40:37,107 - INFO - Loaded 16705 TEST Documents.
2025-12-17 02:40:37,108 - INFO - Doc Example: {'id': '35237', 'title': 'Time constraints on KernelExecute commands or MenuItems?', 'text': "I'm trying to use `Get` to load some pretty substantial packages from a custom menu in the _Mathematica_ toolbar (added via MenuSetup.tr).   The problem is, the standard 5-second evaluation timeout seems to apply to commands executed with `KernelExecute`, so only a fraction of my `Get` is evaluated before the command times out. I'm wondering whether there's an option that can be passed to `KernelExecute` (or to `Item` / `MenuItem`) that will remove that time constraint so that my command can be executed completely."}
2025-12-17 02:40:37,108 - INFO - Loading Queries...
2025-12-17 02:40:38,293 - INFO - Loaded 804 TEST queries.
2025-12-17 02:40:38,293 - INFO - Query Example: {'id': '35544', 'text': 'How to use Automorphisms[] on a graph?'}
2025-12-17 02:40:38,308 - INFO - Running task CQADupstackMathematicaRetrieval (split='test', hf_subset='default')...
2025-12-17 02:40:38,323 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 02:40:38,323 - INFO - Running retrieval task - Searching queries...
2025-12-17 02:40:38,349 - INFO - Using prompt_name='query' for task=CQADupstackMathematicaRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 02:40:41,702 - INFO - Performing full corpus search...
2025-12-17 02:40:41,702 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 02:40:41,703 - INFO - Encoding Batch 1/1...
2025-12-17 02:40:42,087 - INFO - Using prompt_name='document' for task=CQADupstackMathematicaRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 04:38:07,999 - INFO - Computing Similarities...
2025-12-17 04:38:08,576 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 04:38:09,125 - INFO - Running retrieval task - Finished.
2025-12-17 04:38:09,135 - INFO - ✓ Finished evaluation for CQADupstackMathematicaRetrieval
2025-12-17 04:38:12,572 - INFO - Loading qrels...
2025-12-17 04:38:13,779 - INFO - Loaded 1039 TEST qrels.
2025-12-17 04:38:13,779 - INFO - Loading Corpus...
2025-12-17 04:38:17,894 - INFO - Loaded 38316 TEST Documents.
2025-12-17 04:38:17,894 - INFO - Doc Example: {'id': '110557', 'title': 'Representation of SU(3) generators', 'text': "Let's discuss about $SU(3)$. I understand that the most important representations (relevant to physics) are the defining and the adjoint. In the defining representation of $SU(3)$; namely $\\mathbf{3}$, the Gell-Mann matrices are used to represent the generators $$ \\left[T^{A}\\right]_{ij} = \\dfrac{1}{2}\\lambda^{A}, $$ where $T^A$ are the generators and $\\lambda^A$ the Gell-Mann matrices. In adjoint representation, on the other hand, an $\\mathbf{8}$, the generators are represented by matrices according to $$ \\left[ T_{i} \\right]_{jk} = -if_{ijk}, $$ where $f_{ijk}$ are the structure constants. My question is this, how can one represent the generators in the $\\mathbf{10}$ of $SU(3)$, which corresponds to a symmetric tensor with 3 upper or lower indices (or for that matter how to represent the $\\mathbf{6}$ with two symmetric indices). What is the general procedure to represent the generators in an arbitrary representation?"}
2025-12-17 04:38:17,894 - INFO - Loading Queries...
2025-12-17 04:38:19,455 - INFO - Loaded 1039 TEST queries.
2025-12-17 04:38:19,455 - INFO - Query Example: {'id': '110554', 'text': 'Magnetic field resistance material: are there any?'}
2025-12-17 04:38:19,472 - INFO - Running task CQADupstackPhysicsRetrieval (split='test', hf_subset='default')...
2025-12-17 04:38:19,489 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 04:38:19,489 - INFO - Running retrieval task - Searching queries...
2025-12-17 04:38:19,521 - INFO - Using prompt_name='query' for task=CQADupstackPhysicsRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 04:38:23,822 - INFO - Performing full corpus search...
2025-12-17 04:38:23,822 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 04:38:23,822 - INFO - Encoding Batch 1/1...
2025-12-17 04:38:24,677 - INFO - Using prompt_name='document' for task=CQADupstackPhysicsRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 06:08:48,634 - INFO - Computing Similarities...
2025-12-17 06:08:49,481 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 06:08:50,187 - INFO - Running retrieval task - Finished.
2025-12-17 06:08:50,199 - INFO - ✓ Finished evaluation for CQADupstackPhysicsRetrieval
2025-12-17 06:08:51,777 - INFO - Loading qrels...
2025-12-17 06:08:52,892 - INFO - Loaded 876 TEST qrels.
2025-12-17 06:08:52,893 - INFO - Loading Corpus...
2025-12-17 06:08:56,809 - INFO - Loaded 32176 TEST Documents.
2025-12-17 06:08:56,809 - INFO - Doc Example: {'id': '228054', 'title': 'Are (mostly) client-side JavaScript web apps slower or less efficient?', 'text': "I am in the midst of writing a web application for work. Everything is from scratch. I have been a PHP programmer for about 13 years, Node.js programmer for the past 2 years, and have no shortage of experience with JavaScript. I love Node.js, and recently rebuilt the company's API in it... So, in planning this web application, the approach I'm considering is, have the Node.js API for getting data from the server, but render everything in the browser. Use AJAX for retrieving data, History API for loading pages, and a MVC-like pattern for the different components. I have read articles detailing twitters rebuild a few years ago. It was more or less a client-side JavaScript app, but a couple years after launching it, they started moving a lot of processing/rendering back to the server, claiming the app improved dramatically in terms of speed. So, my question is as the title asks, is a client-side centric app substantially slower?"}
2025-12-17 06:08:56,809 - INFO - Loading Queries...
2025-12-17 06:08:58,040 - INFO - Loaded 876 TEST queries.
2025-12-17 06:08:58,041 - INFO - Query Example: {'id': '88392', 'text': 'Why is closure important for JavaScript?'}
2025-12-17 06:08:58,056 - INFO - Running task CQADupstackProgrammersRetrieval (split='test', hf_subset='default')...
2025-12-17 06:08:58,071 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 06:08:58,071 - INFO - Running retrieval task - Searching queries...
2025-12-17 06:08:58,097 - INFO - Using prompt_name='query' for task=CQADupstackProgrammersRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 06:09:01,633 - INFO - Performing full corpus search...
2025-12-17 06:09:01,633 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 06:09:01,633 - INFO - Encoding Batch 1/1...
2025-12-17 06:09:02,364 - INFO - Using prompt_name='document' for task=CQADupstackProgrammersRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 07:25:06,317 - INFO - Computing Similarities...
2025-12-17 07:25:07,041 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 07:25:07,631 - INFO - Running retrieval task - Finished.
2025-12-17 07:25:07,643 - INFO - ✓ Finished evaluation for CQADupstackProgrammersRetrieval
2025-12-17 07:25:08,890 - INFO - Loading qrels...
2025-12-17 07:25:10,136 - INFO - Loaded 652 TEST qrels.
2025-12-17 07:25:10,136 - INFO - Loading Corpus...
2025-12-17 07:25:15,086 - INFO - Loaded 42269 TEST Documents.
2025-12-17 07:25:15,086 - INFO - Doc Example: {'id': '110556', 'title': 'Is this a case for an ordinal logistic regression? Problems interpreting output', 'text': "I'm a beginner in statistics and R, sorry if this question may seem trivial. I've collected data measuring several different parameters in 40 subjects at two time-points (t1 and t2). There are 3 main parameters in which I'm interested, let's call them ParA, ParB, ParC. ParA is a score of disability. It is on an arbitrary scale (so it is an ordinal scale measure, if my understanding is correct) and values range from 0.0 to 10.0. Note that the increments in this scale are by 0.5 unit, so values like, e.g. 1.5 are possible. I have two measures, at t1 and t2, so I can describe at least three variables from ParA: ParA at t1, ParA at t2, and whether a subject progressed or not (0 or 1). Being a ratio scale measure, I think it would not make much sense to compute a difference (eg. ParA at t2 - ParA at t1), but I'm willing to accept suggestions on this matter. ParB and ParC are meausurements of two anatomical structures; they are continuous; Par B is an area measured in mm2, ParC is a volume measured in mm3. I believe they should be considered ratio scale measure. For each one I can describe at least 4 variables: measuments at t1 and t2 (eg. ParB1, ParB2), absolute difference between the two measurements (ParB2-ParB1), percentual difference between the two. What I want to do: I want to do some sort of regression, to see if ParA at t2 is best predicted by B or C (percentual difference, or maybe ParB or ParC at t1, I've yet to decide which makes most sense), but I don't know how to do this. I tried doing some research and concluded that I want to do an ordinal logistic regression, but now I'm unsure how to interpret the results and I'm questioning my choice. Here's some data in case someone wants to reproduce my situation:               require(MASS)          example.df <- data.frame(ParA1=c(1.5,0.0,0.0,1.0,1.5,1.0,1.0,0.0,0.0,0.0,3.0), ParA2 = c(2.5,1.5,1.0,2.0,2.0,1.5,2.0,0.0,0.0,0.0,6.5), Progressed=c(1,1,1,1,1,1,1,0,0,0,1), ParB1=c(222.76,743.07,559.65,642.93,584.36,565.53,590.88,465.31,570.22,543.91,574.80), ParB2=c(214.5,674.71,538.75,560.72,581.9,566.40,499.72, 434.72,528.33,517.61,516.1), ParBAbsolDiff=c(-8.27,-68.36,-20.90,-82.21,-2.46,0.87,-91.16,-30.59,-41.88,-26.31,-58.71), ParBPercentDiff=c(-3.71,-9.20,-3.73,-12.79,-0.42,0.15,-15.43,-6.57,-7.34,-4.84,-10.21), ParC1=c(1585354,1600993,1818728,1595059,1445126,1599984,1454398,1540987,1567783,1559505,1523271), ParC2=c(1578834,1512068,1800791,1514774,1472185,1548337,1440284,1505046,1586734,1622379,1496734), ParCAbsolutDiff=c(-6520.26,-88925.62,-17937.04,-80285.40,27059.77,-51646.81,-14114.52,-35940.91,18951.04,62873.71,-26536.51), ParCPercentDiff=c(-0.41,-5.55,-0.99,-5.03,1.87,-3.23,-0.97,-2.33,1.21,4.03,-1.74))          > myregression <- polr(ParA2 ~ ParBPercentDiff + ParCPercentDiff,data=example.df, Hess=TRUE)     Error in polr(ParA2 ~ ParBPercentDiff + ParCPercentDiff, data = example.df,  :      response must be a factor          > example.df$ParA2 <- factor(example.df$ParA2)     > myregression <- polr(ParA2 ~ ParBPercentDiff + ParCPercentDiff, data=example.df, Hess=TRUE)          > summary(myregression)     Call:     polr(formula = ParA2 ~ ParBPercentDiff + ParCPercentDiff, data = example.df,      Hess = TRUE)          Coefficients:                    Value Std. Error t value     ParBPercentDiff -0.04825     0.1114 -0.4330     ParCPercentDiff -0.13650     0.2079 -0.6566          Intercepts:         Value   Std. Error t value     0|1     -0.4982  0.9546    -0.5219     1|1.5   -0.0267  0.9367    -0.0285     1.5|2    0.7736  0.9874     0.7835     2|2.5    2.1062  1.1628     1.8113     2.5|6.5  2.8957  1.3531     2.1400          Residual Deviance: 35.89846      AIC: 49.89846      > ci <- confint(myregression)     Waiting for profiling to be done...     > exp(cbind(OR= coef(myregression), ci))                        OR     2.5 %   97.5 %     ParBPercentDiff 0.9528960 0.7596362 1.200121     ParCPercentDiff 0.8724038 0.5670611 1.321134      I searched the internet, but I don't understand what I found. There are several questions in stackoverflow, but the answers were too advanced. I'm a medical student, so I have some basics concept in statistics, but this is advanced stuff for my current level of understanding. I'm trying to study statistics in my free time, but at the moment I'm pressed, and I need to understand what this mean; I think it is best if it is explained in simple terms. Getting back to my question... I'm confused by the results I obtained, probably because I'm confused about some underlying concept. What I conclude from looking at summary(myregression) is that ParBPercentDiff is a worse predictor than ParCPercentDiff (a certain increase in ParBPercentDiff gives a decrease of -0.04 in the expected value of ParA2 on the log odds scale - so a decrease of ParBPercentDiff should give an increase of +0.04; these values are higher for ParCPercentDiff); however the OR seems to tell a different story; Like, the odds of ParA2 increasing are greater with an increase in ParBPercentDiff...? My interpretation is surely flawed. I think I could interpret the results more easily if I could plot this regression, but I didn't get what I expected.               myprof <- profile(myregression)     plot(myprof)      So:   * Is ordinal logistic regression really what I want to do in this case?   * If not, what analysis do you suggest?   * If yes, how can I interpret the result I got (please, in simple terms)?"}
2025-12-17 07:25:15,086 - INFO - Loading Queries...
2025-12-17 07:25:16,960 - INFO - Loaded 652 TEST queries.
2025-12-17 07:25:16,960 - INFO - Query Example: {'id': '11546', 'text': 'Tool to confirm Gaussian fit'}
2025-12-17 07:25:16,973 - INFO - Running task CQADupstackStatsRetrieval (split='test', hf_subset='default')...
2025-12-17 07:25:16,986 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 07:25:16,986 - INFO - Running retrieval task - Searching queries...
2025-12-17 07:25:17,008 - INFO - Using prompt_name='query' for task=CQADupstackStatsRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 07:25:19,895 - INFO - Performing full corpus search...
2025-12-17 07:25:19,895 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 07:25:19,895 - INFO - Encoding Batch 1/1...
2025-12-17 07:25:20,861 - INFO - Using prompt_name='document' for task=CQADupstackStatsRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 09:58:08,847 - INFO - Computing Similarities...
2025-12-17 09:58:09,390 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 09:58:09,916 - INFO - Running retrieval task - Finished.
2025-12-17 09:58:09,924 - INFO - ✓ Finished evaluation for CQADupstackStatsRetrieval
2025-12-17 09:58:12,110 - INFO - Loading qrels...
2025-12-17 09:58:13,337 - INFO - Loaded 2906 TEST qrels.
2025-12-17 09:58:13,338 - INFO - Loading Corpus...
2025-12-17 09:58:20,223 - INFO - Loaded 68184 TEST Documents.
2025-12-17 09:58:20,223 - INFO - Doc Example: {'id': '182565', 'title': 'Adding horizontal lines to pgfplots bar', 'text': "I am using a pgfplots stacked bar to display the aggregated energy demand of a houshold and the associated price. When the energy demand exceeds a certain threshold, than a higher price has to be paid. This is visualized by the color red and blue of the bars. The threshold is displayed by the thick red horizontal line. My problem is, that I want this red line to exceed the width of the bar, so that it's width is circa 120 percent of the width of the bar. Is there any possibility to achieve this? Thanks ![enter image description here](http://i.stack.imgur.com/3qeEi.jpg)               \\documentclass[tikz]{standalone}     \\usepackage{pgfplots}     \\pgfplotsset{compat=1.10}     \\begin{document}     \\begin{tikzpicture}     \\begin{axis}[       ymin=0,ymax=4,       samples=3,       enlarge x limits={abs=0.5},       bar width=0.6,       ybar stacked,       legend pos=south east,         every axis/.append style={font=\\footnotesize},     ]          \\draw[red, very thick] (axis cs:0.7,2) -- (axis cs:1.3,2);     \\draw[red, very thick] (axis cs:1.7,2.5) -- (axis cs:2.3,2.5);     \\draw[red, very thick] (axis cs:2.7,2.5) -- (axis cs:3.3,2.5);          \\addplot     coordinates          {(1,1) (2,2.5) (3,1.5)};          \\addplot     coordinates          {(1,0) (2,1) (3,0)};               \\legend{low price, high price}     \\end{axis}     \\end{tikzpicture}     \\end{document}"}
2025-12-17 09:58:20,223 - INFO - Loading Queries...
2025-12-17 09:58:22,265 - INFO - Loaded 2906 TEST queries.
2025-12-17 09:58:22,266 - INFO - Query Example: {'id': '197555', 'text': 'How can I learn to make my own packages?'}
2025-12-17 09:58:22,302 - INFO - Running task CQADupstackTexRetrieval (split='test', hf_subset='default')...
2025-12-17 09:58:22,335 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 09:58:22,335 - INFO - Running retrieval task - Searching queries...
2025-12-17 09:58:22,408 - INFO - Using prompt_name='query' for task=CQADupstackTexRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 09:58:34,393 - INFO - Performing full corpus search...
2025-12-17 09:58:34,393 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 09:58:34,394 - INFO - Encoding Batch 1/2...
2025-12-17 09:58:35,580 - INFO - Using prompt_name='document' for task=CQADupstackTexRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
2025-12-17 14:00:04,360 - INFO - Computing Similarities...
2025-12-17 14:00:06,101 - INFO - Encoding Batch 2/2...
2025-12-17 16:19:32,044 - INFO - Computing Similarities...
2025-12-17 16:19:33,338 - INFO - Running retrieval task - Evaluating retrieval scores...
2025-12-17 16:19:35,537 - INFO - Running retrieval task - Finished.
2025-12-17 16:19:35,576 - INFO - ✓ Finished evaluation for CQADupstackTexRetrieval
2025-12-17 16:19:39,285 - INFO - Loading qrels...
2025-12-17 16:19:40,436 - INFO - Loaded 1072 TEST qrels.
2025-12-17 16:19:40,436 - INFO - Loading Corpus...
2025-12-17 16:19:46,551 - INFO - Loaded 47382 TEST Documents.
2025-12-17 16:19:46,551 - INFO - Doc Example: {'id': '110557', 'title': 'Force ssh to not to print warnings', 'text': 'Is there a way to avoid ssh printing warning messages like this?               "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r",     "@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\\r",     "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\r",      Although the remote host identity has changed but I know it is fine and just want to get rid of this warning.'}
2025-12-17 16:19:46,551 - INFO - Loading Queries...
2025-12-17 16:19:48,317 - INFO - Loaded 1072 TEST queries.
2025-12-17 16:19:48,317 - INFO - Query Example: {'id': '103549', 'text': 'Yanked USB Key During Move'}
2025-12-17 16:19:48,338 - INFO - Running task CQADupstackUnixRetrieval (split='test', hf_subset='default')...
2025-12-17 16:19:48,361 - INFO - Running retrieval task - Indexing corpus...
2025-12-17 16:19:48,362 - INFO - Running retrieval task - Searching queries...
2025-12-17 16:19:48,392 - INFO - Using prompt_name='query' for task=CQADupstackUnixRetrieval prompt_type=<PromptType.query: 'query'> with prompt=''
2025-12-17 16:19:52,817 - INFO - Performing full corpus search...
2025-12-17 16:19:52,817 - INFO - Encoding Corpus in batches (this might take a while)...
2025-12-17 16:19:52,817 - INFO - Encoding Batch 1/1...
2025-12-17 16:19:53,885 - INFO - Using prompt_name='document' for task=CQADupstackUnixRetrieval prompt_type=<PromptType.document: 'document'> with prompt=''
